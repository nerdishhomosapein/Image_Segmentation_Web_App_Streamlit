{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Create-streamlit-app.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCoPy41mecsP"
      },
      "source": [
        "## Running the Streamlit web app from google colab using ngrok tunnel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvlYkCQ9vFiy",
        "outputId": "bc3606ff-06a7-4c36-e163-922c4f06c804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q streamlit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.4MB 6.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7MB 39.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5MB 38.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 53.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 49.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 58.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 53.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 46.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzvl_5Cv8HeX"
      },
      "source": [
        "Reset the execution environment after streamlit installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1sic9Rt0T7l",
        "outputId": "32bbc66a-494e-4c69-dcf0-202894b08ccb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile mysegmentation_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import altair as alt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, urllib, cv2\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Render the readme as markdown using st.markdown.\n",
        "    readme_text = st.markdown(get_file_content_as_string(\"instructions.md\"))\n",
        "\n",
        "    # Download external dependencies.\n",
        "    for filename in EXTERNAL_DEPENDENCIES.keys():\n",
        "        download_file(filename)\n",
        "\n",
        "    st.sidebar.title(\"What to do\")\n",
        "    app_mode = st.sidebar.selectbox(\"Choose the app mode\",\n",
        "        [\"Show instructions\", \"Run the app\", \"Show the source code\"])\n",
        "    if app_mode == \"Show instructions\":\n",
        "        st.sidebar.success('To continue select \"Run the app\".')\n",
        "    elif app_mode == \"Show the source code\":\n",
        "        readme_text.empty()\n",
        "        st.code(get_file_content_as_string(\"mysegmentation_app.py\"))\n",
        "    elif app_mode == \"Run the app\":\n",
        "        readme_text.empty()\n",
        "        run_the_app()\n",
        "\n",
        "# This file downloader demonstrates Streamlit animation.\n",
        "def download_file(file_path):\n",
        "    # Don't download the file twice. (If possible, verify the download using the file length.)\n",
        "    if os.path.exists(file_path):\n",
        "        if \"size\" not in EXTERNAL_DEPENDENCIES[file_path]:\n",
        "            return\n",
        "        elif os.path.getsize(file_path) == EXTERNAL_DEPENDENCIES[file_path][\"size\"]:\n",
        "            return\n",
        "\n",
        "    # These are handles to two visual elements to animate.\n",
        "    weights_warning, progress_bar = None, None\n",
        "    try:\n",
        "        weights_warning = st.warning(\"Downloading %s...\" % file_path)\n",
        "        progress_bar = st.progress(0)\n",
        "        with open(file_path, \"wb\") as output_file:\n",
        "            with urllib.request.urlopen(EXTERNAL_DEPENDENCIES[file_path][\"url\"]) as response:\n",
        "                length = int(response.info()[\"Content-Length\"])\n",
        "                counter = 0.0\n",
        "                MEGABYTES = 2.0 ** 20.0\n",
        "                while True:\n",
        "                    data = response.read(8192)\n",
        "                    if not data:\n",
        "                        break\n",
        "                    counter += len(data)\n",
        "                    output_file.write(data)\n",
        "\n",
        "                    # We perform animation by overwriting the elements.\n",
        "                    weights_warning.warning(\"Downloading %s... (%6.2f/%6.2f MB)\" %\n",
        "                        (file_path, counter / MEGABYTES, length / MEGABYTES))\n",
        "                    progress_bar.progress(min(counter / length, 1.0))\n",
        "\n",
        "    # Finally, we remove these visual elements by calling .empty().\n",
        "    finally:\n",
        "        if weights_warning is not None:\n",
        "            weights_warning.empty()\n",
        "        if progress_bar is not None:\n",
        "            progress_bar.empty()\n",
        "\n",
        "# This is the main app app itself, which appears when the user selects \"Run the app\".\n",
        "def run_the_app():\n",
        "    # To make Streamlit fast, st.cache allows us to reuse computation across runs.\n",
        "    # In this common pattern, we download data from an endpoint only once.\n",
        "    @st.cache\n",
        "    def load_metadata(url):\n",
        "        return pd.read_csv(url)\n",
        "\n",
        "    # This function uses some Pandas magic to summarize the metadata Dataframe.\n",
        "    @st.cache\n",
        "    def create_summary(metadata):\n",
        "        one_hot_encoded = pd.get_dummies(metadata[[\"frame\", \"label\"]], columns=[\"label\"])\n",
        "        summary = one_hot_encoded.groupby([\"frame\"]).sum().rename(columns={\n",
        "            \"label_biker\": \"biker\",\n",
        "            \"label_car\": \"car\",\n",
        "            \"label_pedestrian\": \"pedestrian\",\n",
        "            \"label_trafficLight\": \"traffic light\",\n",
        "            \"label_truck\": \"truck\"\n",
        "        })\n",
        "        return summary\n",
        "\n",
        "    # An amazing property of st.cached functions is that you can pipe them into\n",
        "    # one another to form a computation DAG (directed acyclic graph). Streamlit\n",
        "    # recomputes only whatever subset is required to get the right answer!\n",
        "    metadata = load_metadata(os.path.join(DATA_URL_ROOT, \"labels.csv.gz\"))\n",
        "    summary = create_summary(metadata)\n",
        "\n",
        "    # Uncomment these lines to peek at these DataFrames.\n",
        "    # st.write('## Metadata', metadata[:1000], '## Summary', summary[:1000])\n",
        "\n",
        "    # Draw the UI elements to search for objects (pedestrians, cars, etc.)\n",
        "    selected_frame_index, selected_frame = frame_selector_ui(summary)\n",
        "    if selected_frame_index == None:\n",
        "        st.error(\"No frames fit the criteria. Please select different label or number.\")\n",
        "        return\n",
        "\n",
        "    # Draw the UI element to select parameters for the YOLO object detector.\n",
        "    confidence_threshold, overlap_threshold = object_detector_ui()\n",
        "\n",
        "    # Load the image from S3.\n",
        "    image_url = os.path.join(DATA_URL_ROOT, selected_frame)\n",
        "    image = load_image(image_url)\n",
        "\n",
        "    # Add boxes for objects on the image. These are the boxes for the ground image.\n",
        "    boxes = metadata[metadata.frame == selected_frame].drop(columns=[\"frame\"])\n",
        "    draw_image_with_boxes(image, boxes, \"Ground Truth\",\n",
        "        \"**Human-annotated data** (frame `%i`)\" % selected_frame_index)\n",
        "\n",
        "    # Get the boxes for the objects detected by YOLO by running the YOLO model.\n",
        "    yolo_boxes = yolo_v3(image, confidence_threshold, overlap_threshold)\n",
        "    draw_image_with_boxes(image, yolo_boxes, \"Real-time Computer Vision\",\n",
        "        \"**YOLO v3 Model** (overlap `%3.1f`) (confidence `%3.1f`)\" % (overlap_threshold, confidence_threshold))\n",
        "\n",
        "# This sidebar UI is a little search engine to find certain object types.\n",
        "def frame_selector_ui(summary):\n",
        "    st.sidebar.markdown(\"# Frame\")\n",
        "\n",
        "    # The user can pick which type of object to search for.\n",
        "    object_type = st.sidebar.selectbox(\"Search for which objects?\", summary.columns, 2)\n",
        "\n",
        "    # The user can select a range for how many of the selected objecgt should be present.\n",
        "    min_elts, max_elts = st.sidebar.slider(\"How many %ss (select a range)?\" % object_type, 0, 25, [10, 20])\n",
        "    selected_frames = get_selected_frames(summary, object_type, min_elts, max_elts)\n",
        "    if len(selected_frames) < 1:\n",
        "        return None, None\n",
        "\n",
        "    # Choose a frame out of the selected frames.\n",
        "    selected_frame_index = st.sidebar.slider(\"Choose a frame (index)\", 0, len(selected_frames) - 1, 0)\n",
        "\n",
        "    # Draw an altair chart in the sidebar with information on the frame.\n",
        "    objects_per_frame = summary.loc[selected_frames, object_type].reset_index(drop=True).reset_index()\n",
        "    chart = alt.Chart(objects_per_frame, height=120).mark_area().encode(\n",
        "        alt.X(\"index:Q\", scale=alt.Scale(nice=False)),\n",
        "        alt.Y(\"%s:Q\" % object_type))\n",
        "    selected_frame_df = pd.DataFrame({\"selected_frame\": [selected_frame_index]})\n",
        "    vline = alt.Chart(selected_frame_df).mark_rule(color=\"red\").encode(x = \"selected_frame\")\n",
        "    st.sidebar.altair_chart(alt.layer(chart, vline))\n",
        "\n",
        "    selected_frame = selected_frames[selected_frame_index]\n",
        "    return selected_frame_index, selected_frame\n",
        "\n",
        "# Select frames based on the selection in the sidebar\n",
        "@st.cache(hash_funcs={np.ufunc: str})\n",
        "def get_selected_frames(summary, label, min_elts, max_elts):\n",
        "    return summary[np.logical_and(summary[label] >= min_elts, summary[label] <= max_elts)].index\n",
        "\n",
        "# This sidebar UI lets the user select parameters for the YOLO object detector.\n",
        "def object_detector_ui():\n",
        "    st.sidebar.markdown(\"# Model\")\n",
        "    confidence_threshold = st.sidebar.slider(\"Confidence threshold\", 0.0, 1.0, 0.5, 0.01)\n",
        "    overlap_threshold = st.sidebar.slider(\"Overlap threshold\", 0.0, 1.0, 0.3, 0.01)\n",
        "    return confidence_threshold, overlap_threshold\n",
        "\n",
        "# Draws an image with boxes overlayed to indicate the presence of cars, pedestrians etc.\n",
        "def draw_image_with_boxes(image, boxes, header, description):\n",
        "    # Superpose the semi-transparent object detection boxes.    # Colors for the boxes\n",
        "    LABEL_COLORS = {\n",
        "        \"car\": [255, 0, 0],\n",
        "        \"pedestrian\": [0, 255, 0],\n",
        "        \"truck\": [0, 0, 255],\n",
        "        \"trafficLight\": [255, 255, 0],\n",
        "        \"biker\": [255, 0, 255],\n",
        "    }\n",
        "    image_with_boxes = image.astype(np.float64)\n",
        "    for _, (xmin, ymin, xmax, ymax, label) in boxes.iterrows():\n",
        "        image_with_boxes[int(ymin):int(ymax),int(xmin):int(xmax),:] += LABEL_COLORS[label]\n",
        "        image_with_boxes[int(ymin):int(ymax),int(xmin):int(xmax),:] /= 2\n",
        "\n",
        "    # Draw the header and image.\n",
        "    st.subheader(header)\n",
        "    st.markdown(description)\n",
        "    st.image(image_with_boxes.astype(np.uint8), use_column_width=True)\n",
        "\n",
        "# Download a single file and make its content available as a string.\n",
        "@st.cache(show_spinner=False)\n",
        "def get_file_content_as_string(path):\n",
        "    url = 'https://raw.githubusercontent.com/streamlit/demo-self-driving/master/' + path\n",
        "    response = urllib.request.urlopen(url)\n",
        "    return response.read().decode(\"utf-8\")\n",
        "\n",
        "# This function loads an image from Streamlit public repo on S3. We use st.cache on this\n",
        "# function as well, so we can reuse the images across runs.\n",
        "@st.cache(show_spinner=False)\n",
        "def load_image(url):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        image = np.asarray(bytearray(response.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = image[:, :, [2, 1, 0]] # BGR -> RGB\n",
        "    return image\n",
        "\n",
        "# Run the YOLO model to detect objects.\n",
        "def yolo_v3(image, confidence_threshold, overlap_threshold):\n",
        "    # Load the network. Because this is cached it will only happen once.\n",
        "    @st.cache(allow_output_mutation=True)\n",
        "    def load_network(config_path, weights_path):\n",
        "        net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
        "        output_layer_names = net.getLayerNames()\n",
        "        output_layer_names = [output_layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "        return net, output_layer_names\n",
        "    net, output_layer_names = load_network(\"yolov3.cfg\", \"yolov3.weights\")\n",
        "\n",
        "    # Run the YOLO neural net.\n",
        "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    layer_outputs = net.forward(output_layer_names)\n",
        "\n",
        "    # Supress detections in case of too low confidence or too much overlap.\n",
        "    boxes, confidences, class_IDs = [], [], []\n",
        "    H, W = image.shape[:2]\n",
        "    for output in layer_outputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            classID = np.argmax(scores)\n",
        "            confidence = scores[classID]\n",
        "            if confidence > confidence_threshold:\n",
        "                box = detection[0:4] * np.array([W, H, W, H])\n",
        "                centerX, centerY, width, height = box.astype(\"int\")\n",
        "                x, y = int(centerX - (width / 2)), int(centerY - (height / 2))\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "                confidences.append(float(confidence))\n",
        "                class_IDs.append(classID)\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, overlap_threshold)\n",
        "\n",
        "    # Map from YOLO labels to Udacity labels.\n",
        "    UDACITY_LABELS = {\n",
        "        0: 'pedestrian',\n",
        "        1: 'biker',\n",
        "        2: 'car',\n",
        "        3: 'biker',\n",
        "        5: 'truck',\n",
        "        7: 'truck',\n",
        "        9: 'trafficLight'\n",
        "    }\n",
        "    xmin, xmax, ymin, ymax, labels = [], [], [], [], []\n",
        "    if len(indices) > 0:\n",
        "        # loop over the indexes we are keeping\n",
        "        for i in indices.flatten():\n",
        "            label = UDACITY_LABELS.get(class_IDs[i], None)\n",
        "            if label is None:\n",
        "                continue\n",
        "\n",
        "            # extract the bounding box coordinates\n",
        "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
        "\n",
        "            xmin.append(x)\n",
        "            ymin.append(y)\n",
        "            xmax.append(x+w)\n",
        "            ymax.append(y+h)\n",
        "            labels.append(label)\n",
        "\n",
        "    boxes = pd.DataFrame({\"xmin\": xmin, \"ymin\": ymin, \"xmax\": xmax, \"ymax\": ymax, \"labels\": labels})\n",
        "    return boxes[[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"labels\"]]\n",
        "\n",
        "# Path to the Streamlit public S3 bucket\n",
        "DATA_URL_ROOT = \"https://streamlit-self-driving.s3-us-west-2.amazonaws.com/\"\n",
        "\n",
        "# External files to download.\n",
        "EXTERNAL_DEPENDENCIES = {\n",
        "    \"yolov3.weights\": {\n",
        "        \"url\": \"https://pjreddie.com/media/files/yolov3.weights\",\n",
        "        \"size\": 248007048\n",
        "    },\n",
        "    \"yolov3.cfg\": {\n",
        "        \"url\": \"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\",\n",
        "        \"size\": 8342\n",
        "    }\n",
        "}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting mysegmentation_app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "encqGJ4u0FYG"
      },
      "source": [
        "## Install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPUMEHYwqng",
        "outputId": "cfe61d18-78cc-4a67-b0dd-b8225db8bde4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 03:48:03--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.209.148.13, 54.221.249.251, 34.195.187.253, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.209.148.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  13.9MB/s    in 0.9s    \n",
            "\n",
            "2020-10-29 03:48:04 (13.9 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6679q_6fwsJH",
        "outputId": "6600e009-2693-4ff5-f4d3-32844b4e3dc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGCM2OjvxNit"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxwv00hdxedU"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    'import sys, json; print(\"Execute the next cell and the go to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFvZnzS4vr88",
        "outputId": "6b5ccad0-5346-4630-ca1f-1b981dd47ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!streamlit run /content/mysegmentation_app.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.91.131.158:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}